df_train = df_train %>% mutate(groupe=as.factor(clusters))
vecteur_dates_groupe_1 = df_test[df_test$groupe==1,1]
df_train %>% group_by(groupe) %>% summarise(across(where(is.numeric), list(
moyenne = mean
), na.rm = TRUE))
table(df_train$groupe, df_train$alerte)
set.seed(12)
#On crée un premier modèle qui permet d'attribuer à un cluster chaque observation. Ce faisant, on retrouve une partie de l'information contenue dans nos clusters qui provient de la concentration.
rf.fit_clust = randomForest(`groupe` ~. - Concentration.mg.L - alerte
, data=df_train, ntree=1000, importance=TRUE)
df_test = df_test %>% mutate( groupe = predict(rf.fit_clust,df_test)) #on rajoute les colonnes de groupe (ici ce sont des prédictions) et d'alerte
#Lorsqu'on vérifie manuellement, aucune observation des groupes 2, 3 et 4 ne dépasse les 200 mg/L, la méthode fonctionne bien ici
df_train_2 = df_train %>% filter(!(groupe %in% c(2,3,4))) #car on sait que ces groupes ont alerte = 0
#On pondère les classes d'alerte car elles restent déséquilibrées.
freq <- table(df_train_2$alerte)
inv_freq <- 1 / freq
weights <- inv_freq[as.character(df_train_2$alerte)]
#2nd modèle entraîné uniquement sur le groupe 1
rf.2fit_clust <- ranger(
formula = Concentration.mg.L ~.  - Concentration.mg.L - alerte   #on s'assure qu'on ne prend pas des variables expliquées.
,
data = df_train_2,
num.trees = 1000,
case.weights = weights,
importance = "impurity",   # ou "permutation" pour permutation importance
probability = F    #important pour récuperer les probas ==> le seuil peut être changé manuellement
)
vecteur_dates_groupe_1 = df_test[df_test$groupe==1,1]
df_test$predict = ifelse(df_test$groupe==4 |df_test$groupe==2|df_test$groupe==3 ,0, predict(rf.2fit_clust,df_test)$predictions) #On pose ceci car on n'a pas prédit les valeurs pour les groupes 2 3 4
df_test$predict_alerte=  as.factor(ifelse(df_test$predict>= 200, 1 , 0))
confusionMatrix(df_test$predict_alerte,df_test$alerte) #Pour regarder les performances du modèle
df_plot = df_test %>% filter(predict>0) #df utilisé pour créer les graphiques juste en-dessous
rmse =  sqrt(mean((df_plot$`Concentration.mg.L` - df_plot$predict)^2))
rmse
df_plot$erreur = df_plot$predict-df_plot$Concentration.mg.L
df_plot %>% ggplot(aes(x = Concentration.mg.L, y = erreur)) +
geom_point(alpha = 0.4, color = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
geom_smooth(method = "loess", se = FALSE, color = "black") +
labs(title = "Erreur de prédiction en fonction de la concentration réelle sur le modèle à double régression",
x = "Concentration réelle (mg/L)",
y = "Erreur de prédiction (prédiction - réel)")
df_plot %>% ggplot(aes(x = erreur)) + geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8)
df_plot = df_plot %>% mutate(abs_erreur=abs(erreur))
df_plot %>% ggplot(aes(x = Concentration.mg.L, y = abs_erreur)) +
geom_point(alpha = 0.4, color = "darkorange") +
geom_smooth(method = "loess", se = FALSE, color = "black") +
labs(title = "Erreur absolue vs concentration réelle sur le modèle à double régression",
x = "Concentration réelle (mg/L)",
y = "Erreur absolue")
#Voir chunk 32 pour la tripartition
set.seed(23)
rf.fit.simple= randomForest(Concentration.mg.L ~ Conductivité.µS.cm + temperature  +cumul_glissant_Lantosque_86 , data=df_train_2 )
df_plot$predict=predict(rf.fit.simple,df_plot)
df_plot$alerte= as.factor(ifelse(df_plot$Concentration.mg.L>200,2,  ifelse(df_plot$Concentration.mg.L>=180,1,0)  ) )
df_plot$predict_alerte = as.factor(ifelse(df_plot$predict>200,2,  ifelse(df_plot$predict>=180,1,0)  ) )
df_plot$erreur = df_plot$predict-df_plot$Concentration.mg.L
df_plot$abs_erreur = abs(df_plot$erreur)
df_erreur = df_plot %>% filter(predict_alerte!=alerte)
confusionMatrix(df_plot$predict_alerte,df_plot$alerte)
conf <- as.matrix(confusionMatrix(df_plot$predict_alerte, df_plot$alerte)$table)
conf = conf + matrix(c(112,0,0,0,0,0,0,0,0),nrow=3, byrow=TRUE) #On compte aussi les observations qui sont bien classées juste par groupement
# Matrice de pondération des erreurs (ligne = prédiction, colonne = vérité)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1,   0.9, 0.2,   # prédiction = 0
0.7, 1,   0.4,   # prédiction = 1
0.2, 0.5, 1      # prédiction = 2
), nrow = 3, byrow = TRUE)
# Total des prédictions pondérées correctement
TP_w <- sum(conf * W)
# Total des prédictions possibles (normalisation)
Total_possible <- sum(conf)
# F1 Gravité-Inversée (ou Recall pondéré)
F1_GI <- TP_w / Total_possible
cat("F1-GI (Score de précision pondéré selon la gravité des erreurs) :", round(F1_GI, 4), "\n")
library(nlme)
set.seed(23)
mod <- glm(Concentration.mg.L ~ temperature + Conductivité.µS.cm + cumul_glissant_Lantosque_86 + cumul_glissant_Peone_43 + cumul_glissant_Puget_54 + cumul_glissant_Luceram_55 + cumul_glissant_Coursegoules_87, data = df_train_2, family = gaussian)
plot(mod$fitted.values, resid(mod), xlab = "Valeurs ajustées", ylab = "Résidus")
abline(h = 0, col = "red")
df_plot$predict=predict(mod,df_plot)
df_plot$alerte= as.factor(ifelse(df_plot$Concentration.mg.L>200,2,  ifelse(df_plot$Concentration.mg.L>=180,1,0)  ) )
df_plot$predict_alerte = as.factor(ifelse(df_plot$predict>200,2,  ifelse(df_plot$predict>=180,1,0)  ) )
confusionMatrix(df_plot$predict_alerte,df_plot$alerte) #Le RF et le glm ont des performances quasi égales lorsqu'on classifie post-hoc.Le RF capte des interractions complexes qui le rendent plus performant
df_plot$erreur = df_plot$predict - df_plot$Concentration.mg.L
df_plot %>% ggplot(aes(x = Conductivité.µS.cm, y = erreur)) +geom_point(alpha = 0.4, color = "steelblue")+geom_smooth(method = "loess", se = FALSE, color = "black") + geom_hline(yintercept = 0, linetype = "dashed", color = "red")
conf <- as.matrix(confusionMatrix(df_plot$predict_alerte, df_plot$alerte)$table)
conf = conf + matrix(c(112,0,0,0,0,0,0,0,0),nrow=3, byrow=TRUE) #On compte aussi les observations qui sont bien classées juste par groupement
#Matrice de pondération des erreurs (ligne = prédict, colonne = factuel)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1,   0.9, 0.2,   # prédiction = 0
0.7, 1,   0.4,   # prédiction = 1
0.2, 0.5, 1      # prédiction = 2
), nrow = 3, byrow = TRUE)
# F1 Gravité Inversée
TP_w <- sum(conf * W) #somme des prédictions * leur poids
Total_possible <- sum(conf) #somme des prédictions
F1_GI <- TP_w / Total_possible #ratio des deux qui se lit comme un F1 classique
cat("\n","F1-GI avec pondération :", round(F1_GI, 4))
library(nnet)
set.seed(23)
#choix des var explicatives
cols=c("temperature","Conductivité.µS.cm","cumul_glissant_Peone_43","cumul_glissant_Puget_54","cumul_glissant_Lantosque_86","cumul_glissant_Luceram_55","cumul_glissant_Coursegoules_87")
#pour standariser/déstandariser
means <- sapply(df_train[, cols], mean)
sds <- sapply(df_train[, cols], sd)
#on est obligé de standariser les vars explicatives pour que les neurones fonctionnent correctement
X_train <- scale(df_train[, cols], center = means, scale = sds)
X_test  <- scale(df_plot[, cols], center = means, scale = sds)
y_train <- df_train$Concentration.mg.L #pas besoin pour l'expliquée (pas d'effet d'échelle)
#entraînement du modèle. size = nbr de neurones, maxit = nombre max d'itérations (On pourrait utiliser 250 plutôt que 300, la convergence est rapide), linout = si on veut une régression, decay = coefficient de perte de mémoire à chaque étape (éviter l'overfitting)
nn <- nnet(X_train, y_train, size = 7, maxit = 400, linout = TRUE, decay=0.65)
df_plot$pred_concentration_nnet <- predict(nn, newdata = X_test)
df_plot$erreur_nnet = df_plot$pred_concentration_nnet - df_plot$Concentration.mg.L
df_plot %>% ggplot(aes(x = Concentration.mg.L, y = erreur_nnet)) +geom_point(alpha = 0.4, color = "steelblue")+geom_smooth(method = "loess", se = FALSE, color = "black") + geom_hline(yintercept = 0, linetype = "dashed", color = "red")
summary(nn) #permet de regarder la convergence de l'algo et la tête qu'à chaque neurone
#classification sur les valeurs estimées
df_plot$alerte= as.factor(ifelse(df_plot$Concentration.mg.L>200,2,  ifelse(df_plot$Concentration.mg.L>=180,1,0)  ) )
df_plot$predict_alerte_nnet = as.factor(ifelse(df_plot$pred_concentration_nnet>200,2,  ifelse(df_plot$pred_concentration_nnet>=180,1,0)  ) )
df_plot$erreur = df_plot$pred_concentration_nnet-df_plot$Concentration.mg.L
df_erreur = df_plot %>% filter(predict_alerte_nnet!=alerte)
confusionMatrix(df_plot$predict_alerte_nnet,df_plot$alerte)
conf <- as.matrix(confusionMatrix(df_plot$predict_alerte_nnet, df_plot$alerte)$table)
conf = conf + matrix(c(112,0,0,0,0,0,0,0,0),nrow=3, byrow=TRUE) #On compte aussi les observations qui sont bien classées juste par groupement
#Matrice de pondération des erreurs (ligne = prédict, colonne = factuel)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1,   0.9, 0.2,   # prédiction = 0
0.7, 1,   0.4,   # prédiction = 1
0.2, 0.5, 1      # prédiction = 2
), nrow = 3, byrow = TRUE)
# F1 Gravité Inversée
TP_w <- sum(conf * W) #somme des prédictions * leur poids
Total_possible <- sum(conf) #somme des prédictions
F1_GI <- TP_w / Total_possible #ratio des deux qui se lit comme un F1 classique
cat("\n","F1-GI avec pondération :", round(F1_GI, 4))
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(viridis)
# Étape 1 : transformer la table en matrice
conf_mat <- as.data.frame(conf) %>%
pivot_wider(names_from = Reference, values_from = Freq, values_fill = 0) %>%
column_to_rownames("Prediction") %>%
as.matrix()
# Étape 2 : sommes ligne et colonne
col_sums <- colSums(conf_mat)
# Étape 3 : normalisation corrigée
norm_mat <- matrix(0, nrow = nrow(conf_mat), ncol = ncol(conf_mat),
dimnames = dimnames(conf_mat))
for (i in 1:nrow(conf_mat)) {
for (j in 1:ncol(conf_mat)) {
cell <- conf_mat[i, j]
denom <- col_sums[j]
norm_mat[i, j] <- ifelse(denom == 0, 0, cell / denom)  # éviter division par 0
}
}
# Étape 4 : transformer en format long pour ggplot
norm_df <- as.data.frame(norm_mat) %>%
rownames_to_column("Prediction") %>%
pivot_longer(-Prediction, names_to = "Reference", values_to = "Normalized")
# Étape 5 : afficher avec ggplot2
ggplot(norm_df, aes(x = Reference, y = Prediction, fill = Normalized)) +
geom_raster() +
scale_fill_gradient(low="#00f7ff", high = "darkblue") +
theme_minimal() +
labs(title = "Matrice de confusion normalisée du modèle NNet",
x = "Référence",
y = "Prédiction",
fill = "Ratio") + geom_text(aes(label = round(Normalized, 2)), color = "white", size = 3)
df_double_erreur = df_plot %>% filter(predict_alerte!=alerte & predict_alerte_nnet!=alerte)
df_erreur_rf = df_plot %>% filter(predict_alerte!=alerte)
df_erreur_nnet = df_plot %>% filter(predict_alerte_nnet!=alerte)
df_erreur = df_plot %>% filter(predict_alerte_nnet != alerte | predict_alerte != alerte)
vec_dates = data_S04_Ves_meteo[-index_ech,] %>% dplyr::select(jour)
df_test$jour = vec_dates$jour
vec_dates = df_test[df_test$groupe==1,]$jour
df_plot$jour = vec_dates
ggplot() +
# Ligne pour data_S04_Ves_meteo
geom_line(data = data_S04_Ves_meteo, aes(x = jour, y = Concentration.mg.L), color = "steelblue", size = 1) +
# Points pour df_test
geom_point(data = df_plot, aes(x = jour, y = pred_concentration_nnet), color = "darkorange", size = 2) +
geom_point(data = df_plot, aes(x = jour, y = predict), color = "green", size = 2)
labs(title = "Valeurs prédites projetées sur les valeurs réelles en fonction du temps",
x = "Date",
y = "Valeur prédite") +
theme_minimal()
set.seed(23)
#Split 60%-40%
base_cah_Ray <- rf_dataframe_ray
index_ech <- sample(seq_len(nrow(base_cah_Ray)), size = 0.6 * nrow(base_cah_Ray))
df_train <- base_cah_Ray[index_ech, ]
df_test  <- base_cah_Ray[-index_ech, ]
#Standarisation
vars_predict <- setdiff(names(df_train), "alerte")
scaled_train <- scale(df_train[, vars_predict])
means <- attr(scaled_train, "scaled:center") #Pour pouvoir déstandariser
sds   <- attr(scaled_train, "scaled:scale")
#Créations d'observations avec ROSE
df_train_clust <- as.data.frame(scaled_train)
df_train_clust$alerte <- df_train$alerte
library(ROSE)
df_train_clust <- ROSE(alerte ~ ., data = df_train_clust, seed = 42, N = 400, p = 0.5)$data
#Tri des nouvelles observations pour s'assurer que les données créées sont positives
X_temp <- df_train_clust[, vars_predict]
X_temp <- sweep(X_temp, 2, sds, `*`)
X_temp <- sweep(X_temp, 2, means, `+`)
vars_positives <- c("cumul_glissant_Peone_9", "cumul_glissant_St_martin_9",
"cumul_glissant_Coursegoules_57", "cumul_glissant_St_Et_89")
valid_rows <- apply(X_temp[, vars_positives], 1, function(x) all(x >= 0))
df_train_clust <- df_train_clust[valid_rows, ]
X_temp <- X_temp[valid_rows, ]
#On déstandarise
X_synthetic <- df_train_clust[, vars_predict]
X_synthetic <- sweep(X_synthetic, 2, sds, `*`)
X_synthetic <- sweep(X_synthetic, 2, means, `+`)
#On contstruit le df d'entraînement final
df_train <- cbind(X_synthetic, alerte = df_train_clust$alerte)
vars_positives <- c("cumul_glissant_Peone_9", "cumul_glissant_St_martin_9", "cumul_glissant_Coursegoules_57", "cumul_glissant_St_Et_89")
df_train <- df_train[apply(df_train[, vars_positives], 1, function(x) all(x >= 0)), ]
valid_rows <- apply(df_train[, vars_positives], 1, function(x) all(x >= 0))
df_train <- df_train[valid_rows, ]
#On part de df_train pour ne pas se faire de noeud au CRAN
set.seed(12) #On fixe la graine pour avoir les mêmes clusters à chaque fois
base_cah_Ray <- df_train
df_train_clust = scale(df_train %>% dplyr::select(-alerte)) #df d'entraînement standarisé pour pouvoir être utilisé dans le clustering
#Calcul du dendogramme
mat_distance_Ves=as.dist(gower.dist(df_train_clust)) #on calcule la distance entre nos points d'entraînement
dendo=hclust(mat_distance_Ves,method="ward.D2")
kgs(dendo, mat_distance_Ves, alpha=1, maxclust=10) #nombre opti de clusters = 4
#Visualisation du dendogramme
plot(dendo,labels=FALSE,main="Dendogramme")
rect.hclust(dendo,4,border="blue")
#on ajoute une colonne avec le tag de chaque observation du df d'entraînement non standarisé
clusters = cutree(dendo, k = 4)
df_train = df_train %>% mutate(groupe=as.factor(clusters),alerte = as.factor(ifelse(Concentration.mg.L> 200,1,0)))
#Sur l'échantillon d'entraînement, on a :
#groupe 1 = 50/50
#groupe 2 = ambigu
#groupe 3 = 100% 0
#groupe 4 = 100% 1
df_train_2 = df_train %>% filter(groupe != 3 & groupe != 4) #sous-df d'entrainement
rf.fit_clust = randomForest(`groupe` ~. - Concentration.mg.L - alerte
, data=df_train, ntree=1000, importance=TRUE)
df_test$groupe = predict(rf.fit_clust, df_test)
table(df_train$groupe, df_train$alerte)
table(df_test$groupe, df_test$alerte)
#les groupes 3 et 4 sont purs comme pour le df d'entraînement
#Le groupement fonctionne bien mais on a vraiment trop peu d'observations pour utiliser cette méthode
set.seed(23)
df_train =df_train %>% mutate(alerte=as.factor(ifelse(Concentration.mg.L>200,1,0) ))
df_test = df_test %>% mutate(alerte=as.factor(ifelse(Concentration.mg.L>200,1,0) ))
prop <- prop.table(table(df_train$alerte))
class_weights <- setNames(1 / prop, levels(df_train$alerte))
rf.fit = randomForest(alerte ~.-alerte - Concentration.mg.L ,data=df_train, classwt=class_weights )
df_test$predict_alerte = predict(rf.fit,df_test)
confusionMatrix(df_test$predict_alerte,df_test$alerte)
conf <- as.matrix(confusionMatrix(df_test$predict_alerte,df_test$alerte))
#Matrice de pondération des erreurs (ligne = prédict, colonne = factuel)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1, 0.2,   # prédiction = 0
0.2,  1      # prédiction = 2
), nrow = 2, byrow = TRUE)
# F1 Gravité Inversée
TP_w <- sum(conf * W) #somme des prédictions * leur poids
Total_possible <- sum(conf) #somme des prédictions
F1_GI <- TP_w / Total_possible #ratio des deux qui se lit comme un F1 classique
cat("\n","F1-GI avec pondération :", round(F1_GI, 4))
set.seed(23)
df_train$alerte <- as.factor(df_train$alerte)
#Evluation modèle
logit_model <- glm(alerte ~ . - Concentration.mg.L - alerte - cumul_glissant_St_martin_9    ,
data = df_train,
family = binomial(link = "logit"))
#Coup d'oeil au modèle
summary(logit_model)
probs <- predict(logit_model, newdata = df_test, type = "response")
# Binariser les prédictions avec un seuil (par défaut 0.5)
pred_class <- as.factor(ifelse(probs >= 0.35, 1, 0))
# Afficher la matrice de confusion
confusionMatrix(pred_class,df_test$alerte)
conf <- as.matrix(table(Predicted = pred_class, Actual = df_test$alerte))
#Matrice de pondération des erreurs (ligne = prédict, colonne = factuel)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1,   0.2,    # prédiction = 0
0.2, 1      #prédiction = 1
), nrow = 2, byrow = TRUE)
# F1 Gravité Inversée
TP_w <- sum(conf * W) #somme des prédictions * leur poids
Total_possible <- sum(conf) #somme des prédictions
F1_GI <- TP_w / Total_possible #ratio des deux qui se lit comme un F1 classique
cat("\n","F1-GI avec pondération :", round(F1_GI, 4))
set.seed(23)
rf.fit.simple= randomForest(Concentration.mg.L ~. - Concentration.mg.L - alerte , data=df_train )
df_test$predict=predict(rf.fit.simple,df_test)
df_test$alerte= as.factor(ifelse(df_test$Concentration.mg.L>200, 1,  0) )
df_test$predict_alerte = as.factor(ifelse(df_test$predict>200, 1, 0) )
df_test$erreur = df_test$predict-df_test$Concentration.mg.L
df_test$abs_erreur = abs(df_test$erreur)
df_erreur = df_test %>% filter(predict_alerte!=alerte)
confusionMatrix(df_test$predict_alerte,df_test$alerte)
conf <- as.matrix(confusionMatrix(df_test$predict_alerte, df_test$alerte)$table)
# Matrice de pondération des erreurs (ligne = prédiction, colonne = vérité)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1, 0.2,   # prédiction = 0
0.2,  1      # prédiction = 2
), nrow = 2, byrow = TRUE)
# Total des prédictions pondérées correctement
TP_w <- sum(conf * W)
# Total des prédictions possibles (normalisation)
Total_possible <- sum(conf)
# F1 Gravité-Inversée (ou Recall pondéré)
F1_GI <- TP_w / Total_possible
cat("F1-GI (Score de précision pondéré selon la gravité des erreurs) :", round(F1_GI, 4), "\n")
set.seed(23)
rf.fit.simple= randomForest(Concentration.mg.L ~. - Concentration.mg.L - alerte, data=df_train )
df_test$predict=predict(rf.fit.simple,df_test)
df_test$alerte= as.factor(ifelse(df_test$Concentration.mg.L>200,2,  ifelse(df_test$Concentration.mg.L>=180,1,0)  ) )
df_test$predict_alerte = as.factor(ifelse(df_test$predict>200,2,  ifelse(df_test$predict>=180,1,0)  ) )
df_test$erreur = df_test$predict-df_test$Concentration.mg.L
df_test$abs_erreur = abs(df_test$erreur)
df_erreur = df_test %>% filter(predict_alerte!=alerte)
confusionMatrix(df_test$predict_alerte,df_test$alerte)
conf <- as.matrix(confusionMatrix(df_test$predict_alerte, df_test$alerte)$table)
# Matrice de pondération des erreurs (ligne = prédiction, colonne = vérité)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1,   0.9, 0.2,   # prédiction = 0
0.7, 1,   0.4,   # prédiction = 1
0.2, 0.5, 1      # prédiction = 2
), nrow = 3, byrow = TRUE)
# Total des prédictions pondérées
TP_w <- sum(conf * W)
# Total des prédictions possibles (normalisation)
Total_possible <- sum(conf)
# F1 Gravité-Inversée (ou Recall pondéré)
F1_GI <- TP_w / Total_possible
cat("F1-GI (Score de précision pondéré selon la gravité des erreurs) :", round(F1_GI, 4), "\n")
mse <- mean((df_test$Concentration.mg.L - df_test$predict)^2)
print(mse)
set.seed(23)
mod <- glm(Concentration.mg.L ~ .,
data = subset(df_train, select = -c(alerte)),
family = gaussian)
plot(mod$fitted.values, resid(mod), xlab = "Valeurs ajustées", ylab = "Résidus")
abline(h = 0, col = "red")
summary(mod)
df_test$predict <- predict(mod, newdata = subset(df_test, select = -c(alerte)))
df_test$alerte= as.factor(ifelse(df_test$Concentration.mg.L>200,2,  ifelse(df_test$Concentration.mg.L>=180,1,0)  ) )
df_test$predict_alerte = as.factor(ifelse(df_test$predict>200,2,  ifelse(df_test$predict>=180,1,0)  ) )
confusionMatrix(df_test$predict_alerte,df_test$alerte) #Le RF et le glm ont des performances quasi égales lorsqu'on classifie post-hoc.Le RF capte des interractions complexes qui le rendent plus performant
df_test$erreur = df_test$predict - df_test$Concentration.mg.L
df_test %>% ggplot(aes(x = Concentration.mg.L, y = erreur)) +geom_point(alpha = 0.4, color = "steelblue")+geom_smooth(method = "loess", se = FALSE, color = "black") + geom_hline(yintercept = 0, linetype = "dashed", color = "red")
conf <- as.matrix(confusionMatrix(df_test$predict_alerte, df_test$alerte)$table)
#Matrice de pondération des erreurs (ligne = prédict, colonne = factuel)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1,   0.9, 0.2,   # prédiction = 0
0.7, 1,   0.4,   # prédiction = 1
0.2, 0.5, 1      # prédiction = 2
), nrow = 3, byrow = TRUE)
# F1 Gravité Inversée
TP_w <- sum(conf * W) #somme des prédictions * leur poids
Total_possible <- sum(conf) #somme des prédictions
F1_GI <- TP_w / Total_possible #ratio des deux qui se lit comme un F1 classique
cat("\n","F1-GI avec pondération :", round(F1_GI, 4))
library(nnet)
set.seed(23)
#choix des var explicatives
cols=c("temperature","Conductivité.µS.cm","cumul_glissant_Peone_9","cumul_glissant_St_martin_9","cumul_glissant_St_Et_89","cumul_glissant_Coursegoules_57")
#pour standariser/déstandariser
means <- sapply(df_train[, cols], mean)
sds <- sapply(df_train[, cols], sd)
#on est obligé de standariser les vars explicatives pour que les neurones fonctionnent correctement
X_train <- scale(df_train[, cols], center = means, scale = sds)
X_test  <- scale(df_test[, cols], center = means, scale = sds)
y_train <- df_train$Concentration.mg.L #pas besoin pour l'expliquée (pas d'effet d'échelle)
#entraînement du modèle. size = nbr de neurones, maxit = nombre max d'itérations (On pourrait utiliser 250 plutôt que 300, la convergence est rapide), linout = si on veut une régression, decay = coefficient de perte de mémoire à chaque étape (éviter l'overfitting)
nn <- nnet(X_train, y_train, size = 6, maxit = 400, linout = TRUE, decay=0.3)
#Pour le clustering uniquement
#dummies_train <- model.matrix(~ groupe - 1, data = df_train)
#dummies_test  <- model.matrix(~ groupe - 1, data = df_test)
#X_train <- cbind(X_train, dummies_train)
#X_test  <- cbind(X_test,  dummies_test)
#cols = c("temperature","Conductivité.µS.cm","cumul_glissant_Peone_9","cumul_glissant_St_martin_9","cumul_glissant_St_Et_89","cumul_glissant_Coursegoules_57","groupe1","groupe2","groupe3","groupe4")
df_test$pred_concentration_nnet <- predict(nn, newdata = X_test)
df_test$erreur_nnet = df_test$pred_concentration_nnet - df_test$Concentration.mg.L
df_test %>% ggplot(aes(x = Concentration.mg.L, y = erreur_nnet)) +geom_point(alpha = 0.4, color = "steelblue")+geom_smooth(method = "loess", se = FALSE, color = "black") + geom_hline(yintercept = 0, linetype = "dashed", color = "red")
summary(nn) #permet de regarder la convergence de l'algo et la tête qu'à chaque neurone
#classification sur les valeurs estimées
df_test$alerte= as.factor(ifelse(df_test$Concentration.mg.L>200,2,  ifelse(df_test$Concentration.mg.L>=180,1,0)  ) )
df_test$predict_alerte_nnet = as.factor(ifelse(df_test$pred_concentration_nnet>200,2,  ifelse(df_test$pred_concentration_nnet>=180,1,0)  ) )
df_test$erreur = df_test$pred_concentration_nnet-df_test$Concentration.mg.L
df_erreur = df_test %>% filter(predict_alerte_nnet!=alerte)
confusionMatrix(df_test$predict_alerte_nnet,df_test$alerte)
conf <- as.matrix(confusionMatrix(df_test$predict_alerte_nnet, df_test$alerte)$table)
#Matrice de pondération des erreurs (ligne = prédict, colonne = factuel)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1,   0.9, 0.2,   # prédiction = 0
0.7, 1,   0.4,   # prédiction = 1
0.2, 0.5, 1      # prédiction = 2
), nrow = 3, byrow = TRUE)
# F1 Gravité Inversée
TP_w <- sum(conf * W) #somme des prédictions * leur poids
Total_possible <- sum(conf) #somme des prédictions
F1_GI <- TP_w / Total_possible #ratio des deux qui se lit comme un F1 classique
cat("\n","F1-GI avec pondération :", round(F1_GI, 4))
mse <- mean((df_test$Concentration.mg.L - df_test$pred_concentration_nnet)^2)
print(mse)
set.seed(124) #pour la reproductibilité
rf_dataframe_ves <- data_S04_Ves_meteo %>% filter(year(jour) >= 2017 | month(jour) >= 03) %>% dplyr::select(-c(
Levens,
Nice,
St_Et,
Ascros,
Carros,
Coursegoules,
Lantosque,Le_mas,Luceram,Peone,Puget,Rimplas,Saint_martin_dentraunes, St_martin,cumul_glissant_Ascros_54 , cumul_glissant_Carros_86, cumul_glissant_Le_mas_54 ,  cumul_glissant_Nice_87
, cumul_glissant_St_Et_45 , cumul_glissant_Levens_86, cumul_glissant_Rimplas_55, cumul_glissant_St_martin_87
, cumul_glissant_Saint_martin_dentraunes_43 )) %>% mutate(alerte = as.factor(ifelse(Concentration.mg.L> 200, 1 , 0)))
index_ech = sample(seq_len(nrow(rf_dataframe_ves)), size = 0.8 * nrow(rf_dataframe_ves))
df_train = rf_dataframe_ves[index_ech, ]
df_test = rf_dataframe_ves[-index_ech, ]
library(nnet)
set.seed(23)
#choix des var explicatives pour Raybaud
cols=c("temperature","Conductivité.µS.cm","cumul_glissant_Peone_43","cumul_glissant_Puget_54","cumul_glissant_Lantosque_86","cumul_glissant_Luceram_55","cumul_glissant_Coursegoules_87")
#choix des var explicatives pour Vésubie
cols=c("temperature","Conductivité.µS.cm","cumul_glissant_Peone_43","cumul_glissant_Puget_54","cumul_glissant_Lantosque_86","cumul_glissant_Luceram_55","cumul_glissant_Coursegoules_87")
#pour standariser/déstandariser
means <- sapply(df_train[, cols], mean)
sds <- sapply(df_train[, cols], sd)
#on est obligé de standariser les vars explicatives pour que les neurones fonctionnent correctement
X_train <- scale(df_train[, cols], center = means, scale = sds)
X_test  <- scale(df_test[, cols], center = means, scale = sds)
y_train <- df_train$Concentration.mg.L #pas besoin pour l'expliquée (pas d'effet d'échelle)
#entraînement du modèle. size = nbr de neurones, maxit = nombre max d'itérations (On pourrait utiliser 250 plutôt que 300, la convergence est rapide), linout = si on veut une régression, decay = coefficient de perte de mémoire à chaque étape (éviter l'overfitting)
nn <- nnet(X_train, y_train, size = 7, maxit = 400, linout = TRUE, decay=0.65)
df_train$predict = nn$fitted.values
df_test$predict = predict(nn,X_test)
mse <- mean((df_test$Concentration.mg.L - df_test$predict)^2)
mse
ggplot() +
# Ligne pour data_S04_Ves_meteo
geom_line(data = data_S04_Ves_meteo, aes(x = jour, y = Concentration.mg.L), color = "steelblue", size = 1) +
# Points pour df_test
geom_point(data = df_plot, aes(x = jour, y = predict), color = "darkorange", size = 2) +
geom_point(data = df_plot, aes(x = jour, y = pred_concentration_nnet), color = "green", size = 2) +
labs(title = "Valeurs prédites projetées sur les valeurs réelles en fonction du temps",
x = "Date",
y = "Valeur prédite") +
theme_minimal()
df_test = df_test %>% mutate(alerte = as.factor(ifelse(Concentration.mg.L>200,2,  ifelse(Concentration.mg.L>=180,1,0)  ) ), predict_alerte_nnet = as.factor(ifelse(predict>200,2,  ifelse(predict>=180,1,0)  ) ))
confusionMatrix(df_test$predict_alerte_nnet,df_test$alerte)
data_S04_Ves_meteo = data_S04_Ves_meteo %>% mutate(alerte = as.factor(ifelse(Concentration.mg.L>200,2,ifelse(Concentration.mg.L>=180,1,0) ) ) )
seuil_alerte_2 <- data_S04_Ves_meteo %>%
filter(alerte == 2) %>%
summarise(min_val = min(`Conductivité.µS.cm`, na.rm = TRUE)) %>%
pull(min_val)
# Graphique avec ligne horizontale
ggplot(data = data_S04_Ves_meteo, aes(x = jour, y = `Conductivité.µS.cm`, fill = alerte)) +
geom_point(shape = 21, color = "black", size = 3) +
scale_fill_manual(values = c("0" = "green", "1" = "orange", "2" = "red")) +
geom_hline(yintercept = seuil_alerte_2, linetype = "dashed", color = "red") +
labs(fill = "Alerte",
title = "Conductivité en fonction de la date",
y = "Conductivité (µS/cm)")
library(nnet)
set.seed(23)
#choix des var explicatives
cols=c("temperature","Conductivité.µS.cm","cumul_glissant_Peone_43","cumul_glissant_Puget_54","cumul_glissant_Lantosque_86","cumul_glissant_Luceram_55","cumul_glissant_Coursegoules_87")
#pour standariser/déstandariser
means <- sapply(df_train[, cols], mean)
sds <- sapply(df_train[, cols], sd)
#on est obligé de standariser les vars explicatives pour que les neurones fonctionnent correctement
X_train <- scale(df_train[, cols], center = means, scale = sds)
X_test  <- scale(df_plot[, cols], center = means, scale = sds)
y_train <- df_train$Concentration.mg.L #pas besoin pour l'expliquée (pas d'effet d'échelle)
#entraînement du modèle. size = nbr de neurones, maxit = nombre max d'itérations (On pourrait utiliser 250 plutôt que 300, la convergence est rapide), linout = si on veut une régression, decay = coefficient de perte de mémoire à chaque étape (éviter l'overfitting)
nn <- nnet(X_train, y_train, size = 7, maxit = 400, linout = TRUE, decay=0.65)
df_plot$pred_concentration_nnet <- predict(nn, newdata = X_test)
df_plot$erreur_nnet = df_plot$pred_concentration_nnet - df_plot$Concentration.mg.L
df_plot %>% ggplot(aes(x = Concentration.mg.L, y = erreur_nnet)) +geom_point(alpha = 0.4, color = "steelblue")+geom_smooth(method = "loess", se = FALSE, color = "black") + geom_hline(yintercept = 0, linetype = "dashed", color = "red")
summary(nn) #permet de regarder la convergence de l'algo et la tête qu'à chaque neurone
#classification sur les valeurs estimées
df_plot$alerte= as.factor(ifelse(df_plot$Concentration.mg.L>200,2,  ifelse(df_plot$Concentration.mg.L>=180,1,0)  ) )
df_plot$predict_alerte_nnet = as.factor(ifelse(df_plot$pred_concentration_nnet>200,2,  ifelse(df_plot$pred_concentration_nnet>=180,1,0)  ) )
df_plot$erreur = df_plot$pred_concentration_nnet-df_plot$Concentration.mg.L
df_erreur = df_plot %>% filter(predict_alerte_nnet!=alerte)
confusionMatrix(df_plot$predict_alerte_nnet,df_plot$alerte)
conf <- as.matrix(confusionMatrix(df_plot$predict_alerte_nnet, df_plot$alerte)$table)
conf = conf + matrix(c(112,0,0,0,0,0,0,0,0),nrow=3, byrow=TRUE) #On compte aussi les observations qui sont bien classées juste par groupement
#Matrice de pondération des erreurs (ligne = prédict, colonne = factuel)
# 1 = erreur légère, 0 = erreur très grave
W <- matrix(c(
1,   0.9, 0.2,   # prédiction = 0
0.7, 1,   0.4,   # prédiction = 1
0.2, 0.5, 1      # prédiction = 2
), nrow = 3, byrow = TRUE)
# F1 Gravité Inversée
TP_w <- sum(conf * W) #somme des prédictions * leur poids
Total_possible <- sum(conf) #somme des prédictions
F1_GI <- TP_w / Total_possible #ratio des deux qui se lit comme un F1 classique
cat("\n","F1-GI avec pondération :", round(F1_GI, 4))
